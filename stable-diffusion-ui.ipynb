{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy05gVAxujEu"
   },
   "outputs": [],
   "source": [
    "# @title **セットアップ**\n",
    "\n",
    "! pip install transformers gradio scipy ftfy \"ipywidgets>=7,<8\" datasets\n",
    "! pip install git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Gfa6bXjujEz"
   },
   "outputs": [],
   "source": [
    "# @title **ログイン**\n",
    "# @markdown - 事前にHagging Faceでトークンを取得しておいて下さい\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WVxJG9ghujE1"
   },
   "outputs": [],
   "source": [
    "# @title **セットアップ 2**\n",
    "# @markdown 画像ファイルをファイルに保存する場合はチェックを入れてください。\n",
    "from glob import glob\n",
    "from os import makedirs, path\n",
    "from typing import Union\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "\n",
    "output = \"./output\"\n",
    "pipe: Union[StableDiffusionPipeline, StableDiffusionImg2ImgPipeline] = None\n",
    "save_image = True  # @param{type: \"boolean\"}\n",
    "\n",
    "\n",
    "def save_images(images: list):\n",
    "    length = len(glob(path.join(output, \"*.png\"))) + 1\n",
    "    if not path.exists(output):\n",
    "        makedirs(output)\n",
    "    for idx, image in enumerate(images):\n",
    "        image.save(path.join(output, f\"result-{length + idx}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPf0_VmfujE2"
   },
   "outputs": [],
   "source": [
    "# @title **メインプログラム**\n",
    "# @markdown img2imgを利用したい場合は一つ下のプログラムを実行してください。\n",
    "import gradio as gr\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "if type(pipe) != StableDiffusionPipeline:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"CompVis/stable-diffusion-v1-4\",\n",
    "        revision=\"fp16\",\n",
    "        torch_dtype=torch.float16,\n",
    "        use_auth_token=True,\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "block = gr.Blocks(css=\".container { max-width: 800px; margin: auto; }\")\n",
    "\n",
    "\n",
    "def infer(\n",
    "    prompt, height, width, seed, num_of_images, num_inference_steps, guidance_scale\n",
    "):\n",
    "    prompt = prompt.replace(\"\\n\", \" \")\n",
    "    images = []\n",
    "    with autocast(\"cuda\"):\n",
    "        generator = torch.Generator(\"cuda\")\n",
    "        if seed:\n",
    "            generator.manual_seed(int(seed))\n",
    "        for i in range(int(num_of_images)):\n",
    "            images.append(\n",
    "                pipe(\n",
    "                    [prompt],\n",
    "                    height=int(height),\n",
    "                    width=int(width),\n",
    "                    num_inference_steps=num_inference_steps,\n",
    "                    guidance_scale=guidance_scale,\n",
    "                    generator=generator,\n",
    "                )[\"sample\"][0]\n",
    "            )\n",
    "    if save_image:\n",
    "        save_images(images)\n",
    "    return {preview: images, prompt_used: prompt, seed_used: generator.initial_seed()}\n",
    "\n",
    "\n",
    "with block as demo:\n",
    "    gr.Markdown(\"<h1>Stable Diffusion UI</h1>\")\n",
    "    with gr.Group():\n",
    "        with gr.Box():\n",
    "            with gr.Row().style(mobile_collapse=False, equal_height=True):\n",
    "                text_box = gr.Textbox(\n",
    "                    label=\"Enter your prompt\", show_label=False\n",
    "                ).style(\n",
    "                    border=True,\n",
    "                    rounded=True,\n",
    "                    container=False,\n",
    "                )\n",
    "                btn = gr.Button(\"Run\").style(\n",
    "                    rounded=True,\n",
    "                )\n",
    "\n",
    "        height_box = gr.Number(label=\"Height\", value=512)\n",
    "        width_box = gr.Number(label=\"Width\", value=512)\n",
    "        seed_box = gr.Textbox(label=\"Seed\")\n",
    "        num_of_images_box = gr.Number(label=\"Number of images\", value=1)\n",
    "        num_inference_steps_box = gr.Slider(\n",
    "            label=\"Steps\", maximum=150, value=50, step=1\n",
    "        )\n",
    "        guidance_scale_box = gr.Slider(\n",
    "            label=\"Cfg Scale\", maximum=20, value=7.5, step=0.5\n",
    "        )\n",
    "\n",
    "        with gr.Box():\n",
    "            preview = gr.Gallery(label=\"Preview\").style(grid=[2], height=\"auto\")\n",
    "            prompt_used = gr.Textbox(label=\"Prompt\", interactive=False).style(\n",
    "                border=True,\n",
    "                rounded=True,\n",
    "                container=False,\n",
    "            )\n",
    "            seed_used = gr.Textbox(label=\"Seed\").style(\n",
    "                border=True,\n",
    "                rounded=True,\n",
    "                container=False,\n",
    "            )\n",
    "\n",
    "    btn.click(\n",
    "        infer,\n",
    "        inputs=[\n",
    "            text_box,\n",
    "            height_box,\n",
    "            width_box,\n",
    "            seed_box,\n",
    "            num_of_images_box,\n",
    "            num_inference_steps_box,\n",
    "            guidance_scale_box,\n",
    "        ],\n",
    "        outputs=[preview, prompt_used, seed_used],\n",
    "    )\n",
    "\n",
    "clear_output()\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zRCE4h4gujE4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7314ca6302264f9eaa347ab32275aeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x171ee2287c8>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title **メインプログラム | Img2Img**\n",
    "import gradio as gr\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img import preprocess\n",
    "from IPython.display import clear_output\n",
    "\n",
    "if type(pipe) != StableDiffusionImg2ImgPipeline:\n",
    "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        \"CompVis/stable-diffusion-v1-4\",\n",
    "        revision=\"fp16\",\n",
    "        torch_dtype=torch.float16,\n",
    "        use_auth_token=True,\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "block = gr.Blocks(css=\".container { max-width: 800px; margin: auto; }\")\n",
    "\n",
    "\n",
    "def infer(\n",
    "    prompt,\n",
    "    seed,\n",
    "    num_of_images,\n",
    "    num_inference_steps,\n",
    "    guidance_scale,\n",
    "    init_image,\n",
    "    strength,\n",
    "):\n",
    "    prompt = prompt.replace(\"\\n\", \" \")\n",
    "    init_image = init_image.resize((512, 512))\n",
    "    init_image = preprocess(init_image)\n",
    "    images = []\n",
    "    with autocast(\"cuda\"):\n",
    "        generator = torch.Generator(\"cuda\")\n",
    "        if seed:\n",
    "            generator.manual_seed(int(seed))\n",
    "        for i in range(int(num_of_images)):\n",
    "            images.append(\n",
    "                pipe(\n",
    "                    [prompt],\n",
    "                    num_inference_steps=num_inference_steps,\n",
    "                    guidance_scale=guidance_scale,\n",
    "                    init_image=init_image,\n",
    "                    strength=strength,\n",
    "                    generator=generator,\n",
    "                )[\"sample\"][0]\n",
    "            )\n",
    "    if save_image:\n",
    "        save_images(images)\n",
    "    return {preview: images, prompt_used: prompt, seed_used: generator.initial_seed()}\n",
    "\n",
    "\n",
    "with block as demo:\n",
    "    gr.Markdown(\"<h1>Stable Diffusion UI - Img2Img</h1>\")\n",
    "    with gr.Group():\n",
    "        with gr.Box():\n",
    "            with gr.Row().style(mobile_collapse=False, equal_height=True):\n",
    "                text = gr.Textbox(label=\"Enter your prompt\", show_label=False).style(\n",
    "                    border=True,\n",
    "                    rounded=True,\n",
    "                    container=False,\n",
    "                )\n",
    "                btn = gr.Button(\"Run\").style(\n",
    "                    rounded=True,\n",
    "                )\n",
    "        seed_box = gr.Textbox(label=\"Seed\")\n",
    "        num_of_images_box = gr.Number(label=\"Number of images\", value=1)\n",
    "        num_inference_steps_box = gr.Slider(\n",
    "            label=\"Steps\", maximum=150, value=50, step=1\n",
    "        )\n",
    "        guidance_scale_box = gr.Slider(\n",
    "            label=\"Cfg Scale\", maximum=20, value=7.5, step=0.5\n",
    "        )\n",
    "\n",
    "        image_box = gr.Image(label=\"Intial Image\", type=\"pil\")\n",
    "        strength_slider_box = gr.Slider(label=\"Strength\", maximum=1, value=0.75)\n",
    "\n",
    "        with gr.Box():\n",
    "            preview = gr.Gallery(label=\"Preview\").style(grid=[2], height=\"auto\")\n",
    "            prompt_used = gr.Textbox(label=\"Prompt\", interactive=False).style(\n",
    "                border=True,\n",
    "                rounded=True,\n",
    "                container=False,\n",
    "            )\n",
    "            seed_used = gr.Textbox(label=\"Seed\").style(\n",
    "                border=True,\n",
    "                rounded=True,\n",
    "                container=False,\n",
    "            )\n",
    "\n",
    "    btn.click(\n",
    "        infer,\n",
    "        inputs=[\n",
    "            text,\n",
    "            seed_box,\n",
    "            num_of_images_box,\n",
    "            num_inference_steps_box,\n",
    "            guidance_scale_box,\n",
    "            image_box,\n",
    "            strength_slider_box,\n",
    "        ],\n",
    "        outputs=[preview, prompt_used, seed_used],\n",
    "    )\n",
    "\n",
    "clear_output()\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stable-diffusion-ui.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/ddPn08/notebooks/blob/main/stable-diffusion-ui.ipynb",
     "timestamp": 1661577450395
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.12 ('env-diffusers')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9022d634aa92bf7fca9a2099f185b366bf6edf95be52e1e5ddf901ae940aeb1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
